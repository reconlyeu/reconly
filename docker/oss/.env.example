# Reconly OSS - Docker Environment Configuration
# Copy this file to .env and configure your settings

# =============================================================================
# Quick Start
# =============================================================================

# Load sample data on first start (recommended for trying out Reconly)
# Set to true to populate feeds, sources, and example digests
LOAD_SAMPLE_DATA=true

# Server port
API_PORT=8000

# =============================================================================
# LLM Provider - Ollama (recommended for local/OSS use)
# =============================================================================
#
# PREREQUISITES - Run these commands BEFORE starting Reconly:
#   1. Install Ollama: https://ollama.com/download
#   2. Pull a model:   ollama pull qwen2.5:7b
#
DEFAULT_PROVIDER=ollama
OLLAMA_MODEL=qwen2.5:7b
OLLAMA_HOST=http://host.docker.internal:11434

# =============================================================================
# Alternative LLM Providers (cloud-based)
# =============================================================================

# Anthropic Claude
# ANTHROPIC_API_KEY=sk-ant-...

# OpenAI
# OPENAI_API_KEY=sk-...

# HuggingFace
# HUGGINGFACE_API_KEY=hf_...

# =============================================================================
# Edition & Security
# =============================================================================

# Edition (oss or enterprise)
RECONLY_EDITION=oss

# Optional: Password protection for the UI
# Leave empty for no authentication
# RECONLY_AUTH_PASSWORD=your-secret-password
