# Reconly OSS - Docker Environment Configuration
# Copy this file to .env and configure your settings

# =============================================================================
# Quick Start
# =============================================================================

# Load sample data on first start (recommended for trying out Reconly)
# Set to true to populate feeds, sources, and example digests
LOAD_SAMPLE_DATA=true

# Server port
API_PORT=8000

# =============================================================================
# LLM Providers (configure at least one for AI features)
# =============================================================================

# Ollama (local, recommended for OSS)
# Run Ollama on your host machine: ollama serve
# Then pull a model: ollama pull llama3.2
DEFAULT_PROVIDER=ollama
# OLLAMA_HOST=http://host.docker.internal:11434

# Anthropic Claude
# ANTHROPIC_API_KEY=sk-ant-...

# OpenAI
# OPENAI_API_KEY=sk-...

# HuggingFace
# HUGGINGFACE_API_KEY=hf_...

# =============================================================================
# Edition & Security
# =============================================================================

# Edition (oss or enterprise)
RECONLY_EDITION=oss

# Optional: Password protection for the UI
# Leave empty for no authentication
# RECONLY_AUTH_PASSWORD=your-secret-password
