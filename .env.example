# Reconly OSS Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# Edition & Authentication
# =============================================================================

# Backend edition: oss (default) or enterprise
RECONLY_EDITION=oss

# Frontend edition (for UI builds): oss (default) or enterprise
VITE_EDITION=oss

# Optional password protection for OSS deployments
# When set, users must authenticate before accessing the API/UI
# RECONLY_AUTH_PASSWORD=your-secure-password

# =============================================================================
# LLM Providers
# =============================================================================

# Default provider: ollama, lmstudio, huggingface, openai, anthropic
DEFAULT_PROVIDER=ollama
DEFAULT_MODEL=phi3:mini
DEFAULT_LANGUAGE=en

# Ollama (local LLM - no API key needed)
OLLAMA_BASE_URL=http://localhost:11434

# LMStudio (local LLM with OpenAI-compatible API - no API key needed)
# LMSTUDIO_BASE_URL=http://localhost:1234/v1
# LMSTUDIO_MODEL=your-loaded-model
# LMSTUDIO_EMBEDDING_MODEL=nomic-embed-text
# PROVIDER_TIMEOUT_LMSTUDIO=300

# OpenAI
# OPENAI_API_KEY=your-openai-api-key

# Anthropic Claude
# ANTHROPIC_API_KEY=your-anthropic-api-key

# HuggingFace
# HUGGINGFACE_API_KEY=your-huggingface-token

# =============================================================================
# Embeddings (RAG)
# =============================================================================

# Embedding provider for RAG knowledge base (ollama, openai, huggingface)
EMBEDDING_PROVIDER=ollama

# Embedding model for the selected provider
# Ollama: bge-m3, nomic-embed-text, mxbai-embed-large
# OpenAI: text-embedding-3-small, text-embedding-3-large
EMBEDDING_MODEL=bge-m3

# Chunking settings for text splitting before embedding
# EMBEDDING_CHUNK_SIZE=384
# EMBEDDING_CHUNK_OVERLAP=64
# EMBEDDING_BATCH_SIZE=32

# =============================================================================
# RSS Fetching
# =============================================================================

# Max age (in days) for articles on first feed run
# Prevents fetching hundreds of old articles when adding a new feed
# Set to 0 to fetch all articles (not recommended for consolidated digests)
RSS_FIRST_RUN_MAX_AGE_DAYS=3

# =============================================================================
# Email (SMTP) - for digest delivery
# =============================================================================

SMTP_HOST=smtp.example.com
SMTP_PORT=587
SMTP_USER=your-email@example.com
SMTP_PASSWORD=your-password
SMTP_FROM_EMAIL=noreply@reconly.eu
SMTP_FROM_NAME=Reconly

# =============================================================================
# Database (PostgreSQL required)
# =============================================================================

DATABASE_URL=postgresql://reconly:reconly_dev@localhost:5432/reconly

# =============================================================================
# Security (REQUIRED for production)
# =============================================================================

# Environment: development or production
# In production mode, SECRET_KEY validation is enforced
RECONLY_ENV=development

# Secret key for session signing and token generation
# REQUIRED: Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"
# Minimum 32 characters required in production
SECRET_KEY=

# Content Security Policy (optional - uses sensible defaults)
# CSP_POLICY=default-src 'self'; script-src 'self' 'unsafe-inline' 'unsafe-eval'; style-src 'self' 'unsafe-inline'; img-src 'self' data: blob:; font-src 'self' data:; connect-src 'self'

# =============================================================================
# Application
# =============================================================================

DEBUG=false

# CORS origins (comma-separated) - includes Astro dev server port
CORS_ORIGINS=http://localhost:3000,http://localhost:4321,http://localhost:8000

# Rate limiting
RATE_LIMIT_PER_MINUTE=60

# =============================================================================
# Scheduler (optional)
# =============================================================================

# Timezone for cron schedules (default: system local timezone)
# Examples: Europe/Berlin, America/New_York, UTC
# SCHEDULER_TIMEZONE=Europe/Berlin

# =============================================================================
# Agent Source (AI Research)
# =============================================================================

# Search provider: "duckduckgo" (default, no setup required),
#                  "searxng" (self-hosted), or "tavily" (API key required)
AGENT_SEARCH_PROVIDER=duckduckgo

# SearXNG URL (only needed if AGENT_SEARCH_PROVIDER=searxng)
# SEARXNG_URL=http://localhost:8080

# Tavily API key (only needed if AGENT_SEARCH_PROVIDER=tavily)
# Get your free API key at https://tavily.com/
# TAVILY_API_KEY=tvly-your-api-key

# Max search results per query (default: 10)
# AGENT_MAX_SEARCH_RESULTS=10

# Default max iterations for agent loops (default: 5)
# AGENT_DEFAULT_MAX_ITERATIONS=5

# =============================================================================
# LLM Chat
# =============================================================================

# Default chat provider (ollama, openai, anthropic, lmstudio)
# If not set, uses first available provider from the fallback chain
# DEFAULT_CHAT_PROVIDER=ollama
